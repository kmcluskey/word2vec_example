{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec\n",
    "\n",
    "This notebook is modestly adapted from: https://github.com/kavgan/nlp-text-mining-working-examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports needed and logging\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import gzip\n",
    "import gensim \n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and logging\n",
    "Read in the dataset. The dataset has full user reviews of cars and hotels, where each line of the file represents a hotel review. Printing a single line of the dataser below shows a rather wordy hotel review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"Oct 12 2009 \\tNice trendy hotel location not too bad.\\tI stayed in this hotel for one night. As this is a fairly new place some of the taxi drivers did not know where it was and/or did not want to drive there. Once I have eventually arrived at the hotel, I was very pleasantly surprised with the decor of the lobby/ground floor area. It was very stylish and modern. I found the reception's staff geeting me with 'Aloha' a bit out of place, but I guess they are briefed to say that to keep up the coroporate image.As I have a Starwood Preferred Guest member, I was given a small gift upon-check in. It was only a couple of fridge magnets in a gift box, but nevertheless a nice gesture.My room was nice and roomy, there are tea and coffee facilities in each room and you get two complimentary bottles of water plus some toiletries by 'bliss'.The location is not great. It is at the last metro stop and you then need to take a taxi, but if you are not planning on going to see the historic sites in Beijing, then you will be ok.I chose to have some breakfast in the hotel, which was really tasty and there was a good selection of dishes. There are a couple of computers to use in the communal area, as well as a pool table. There is also a small swimming pool and a gym area.I would definitely stay in this hotel again, but only if I did not plan to travel to central Beijing, as it can take a long time. The location is ok if you plan to do a lot of shopping, as there is a big shopping centre just few minutes away from the hotel and there are plenty of eating options around, including restaurants that serve a dog meat!\\t\\r\\n\"\n"
     ]
    }
   ],
   "source": [
    "data_file ='../inputs/reviews_data.txt.gz'\n",
    "\n",
    "with gzip.open ('../inputs/reviews_data.txt.gz', 'rb') as f:\n",
    "    for i,line in enumerate (f):\n",
    "        print(line)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read files into a list\n",
    "Read the file into a list so that it can be used to pass on to the Word2Vec model. \n",
    "\n",
    "Pre-processing of the reviews is carried out using gensim.utils.simple_preprocess. \n",
    "This does some basic pre-processing such as tokenization, lowercasing, etc and returns back a \n",
    "list of tokens (words). \n",
    "Documentation of this pre-processing method can be found on the official Gensim documentation site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  read_input(input_file):\n",
    "    \"\"\"This method reads the input file which is in gzip format\"\"\"\n",
    "    \n",
    "    logging.info(\"reading file {0}...this may take a while\".format(input_file))\n",
    "    \n",
    "    with gzip.open (input_file, 'rb') as f:\n",
    "        for i, line in enumerate (f): \n",
    "\n",
    "            if (i%10000==0):\n",
    "                logging.info (\"read {0} reviews\".format (i))\n",
    "            # do some pre-processing and return a list of words for each review text\n",
    "            yield gensim.utils.simple_preprocess (line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-23 10:57:21,292 : INFO : reading file ../inputs/reviews_data.txt.gz...this may take a while\n",
      "2018-10-23 10:57:21,294 : INFO : read 0 reviews\n",
      "2018-10-23 10:57:24,241 : INFO : read 10000 reviews\n",
      "2018-10-23 10:57:27,250 : INFO : read 20000 reviews\n",
      "2018-10-23 10:57:31,044 : INFO : read 30000 reviews\n",
      "2018-10-23 10:57:34,287 : INFO : read 40000 reviews\n",
      "2018-10-23 10:57:37,942 : INFO : read 50000 reviews\n",
      "2018-10-23 10:57:41,566 : INFO : read 60000 reviews\n",
      "2018-10-23 10:57:44,773 : INFO : read 70000 reviews\n",
      "2018-10-23 10:57:47,415 : INFO : read 80000 reviews\n",
      "2018-10-23 10:57:50,307 : INFO : read 90000 reviews\n",
      "2018-10-23 10:57:53,154 : INFO : read 100000 reviews\n",
      "2018-10-23 10:57:55,911 : INFO : read 110000 reviews\n",
      "2018-10-23 10:57:58,829 : INFO : read 120000 reviews\n",
      "2018-10-23 10:58:01,856 : INFO : read 130000 reviews\n",
      "2018-10-23 10:58:05,017 : INFO : read 140000 reviews\n",
      "2018-10-23 10:58:07,846 : INFO : read 150000 reviews\n",
      "2018-10-23 10:58:11,066 : INFO : read 160000 reviews\n",
      "2018-10-23 10:58:13,748 : INFO : read 170000 reviews\n",
      "2018-10-23 10:58:16,627 : INFO : read 180000 reviews\n",
      "2018-10-23 10:58:19,519 : INFO : read 190000 reviews\n",
      "2018-10-23 10:58:22,839 : INFO : read 200000 reviews\n",
      "2018-10-23 10:58:26,053 : INFO : read 210000 reviews\n",
      "2018-10-23 10:58:29,212 : INFO : read 220000 reviews\n",
      "2018-10-23 10:58:32,198 : INFO : read 230000 reviews\n",
      "2018-10-23 10:58:35,152 : INFO : read 240000 reviews\n",
      "2018-10-23 10:58:38,849 : INFO : read 250000 reviews\n",
      "2018-10-23 10:58:40,441 : INFO : Done reading data file\n"
     ]
    }
   ],
   "source": [
    "# read the tokenized reviews into a list\n",
    "# such that documents is a list of lists\n",
    "documents = list (read_input (data_file))\n",
    "logging.info (\"Done reading data file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['oct',\n",
       " 'nice',\n",
       " 'trendy',\n",
       " 'hotel',\n",
       " 'location',\n",
       " 'not',\n",
       " 'too',\n",
       " 'bad',\n",
       " 'stayed',\n",
       " 'in',\n",
       " 'this',\n",
       " 'hotel',\n",
       " 'for',\n",
       " 'one',\n",
       " 'night',\n",
       " 'as',\n",
       " 'this',\n",
       " 'is',\n",
       " 'fairly',\n",
       " 'new',\n",
       " 'place',\n",
       " 'some',\n",
       " 'of',\n",
       " 'the',\n",
       " 'taxi',\n",
       " 'drivers',\n",
       " 'did',\n",
       " 'not',\n",
       " 'know',\n",
       " 'where',\n",
       " 'it',\n",
       " 'was',\n",
       " 'and',\n",
       " 'or',\n",
       " 'did',\n",
       " 'not',\n",
       " 'want',\n",
       " 'to',\n",
       " 'drive',\n",
       " 'there',\n",
       " 'once',\n",
       " 'have',\n",
       " 'eventually',\n",
       " 'arrived',\n",
       " 'at',\n",
       " 'the',\n",
       " 'hotel',\n",
       " 'was',\n",
       " 'very',\n",
       " 'pleasantly',\n",
       " 'surprised',\n",
       " 'with',\n",
       " 'the',\n",
       " 'decor',\n",
       " 'of',\n",
       " 'the',\n",
       " 'lobby',\n",
       " 'ground',\n",
       " 'floor',\n",
       " 'area',\n",
       " 'it',\n",
       " 'was',\n",
       " 'very',\n",
       " 'stylish',\n",
       " 'and',\n",
       " 'modern',\n",
       " 'found',\n",
       " 'the',\n",
       " 'reception',\n",
       " 'staff',\n",
       " 'geeting',\n",
       " 'me',\n",
       " 'with',\n",
       " 'aloha',\n",
       " 'bit',\n",
       " 'out',\n",
       " 'of',\n",
       " 'place',\n",
       " 'but',\n",
       " 'guess',\n",
       " 'they',\n",
       " 'are',\n",
       " 'briefed',\n",
       " 'to',\n",
       " 'say',\n",
       " 'that',\n",
       " 'to',\n",
       " 'keep',\n",
       " 'up',\n",
       " 'the',\n",
       " 'coroporate',\n",
       " 'image',\n",
       " 'as',\n",
       " 'have',\n",
       " 'starwood',\n",
       " 'preferred',\n",
       " 'guest',\n",
       " 'member',\n",
       " 'was',\n",
       " 'given',\n",
       " 'small',\n",
       " 'gift',\n",
       " 'upon',\n",
       " 'check',\n",
       " 'in',\n",
       " 'it',\n",
       " 'was',\n",
       " 'only',\n",
       " 'couple',\n",
       " 'of',\n",
       " 'fridge',\n",
       " 'magnets',\n",
       " 'in',\n",
       " 'gift',\n",
       " 'box',\n",
       " 'but',\n",
       " 'nevertheless',\n",
       " 'nice',\n",
       " 'gesture',\n",
       " 'my',\n",
       " 'room',\n",
       " 'was',\n",
       " 'nice',\n",
       " 'and',\n",
       " 'roomy',\n",
       " 'there',\n",
       " 'are',\n",
       " 'tea',\n",
       " 'and',\n",
       " 'coffee',\n",
       " 'facilities',\n",
       " 'in',\n",
       " 'each',\n",
       " 'room',\n",
       " 'and',\n",
       " 'you',\n",
       " 'get',\n",
       " 'two',\n",
       " 'complimentary',\n",
       " 'bottles',\n",
       " 'of',\n",
       " 'water',\n",
       " 'plus',\n",
       " 'some',\n",
       " 'toiletries',\n",
       " 'by',\n",
       " 'bliss',\n",
       " 'the',\n",
       " 'location',\n",
       " 'is',\n",
       " 'not',\n",
       " 'great',\n",
       " 'it',\n",
       " 'is',\n",
       " 'at',\n",
       " 'the',\n",
       " 'last',\n",
       " 'metro',\n",
       " 'stop',\n",
       " 'and',\n",
       " 'you',\n",
       " 'then',\n",
       " 'need',\n",
       " 'to',\n",
       " 'take',\n",
       " 'taxi',\n",
       " 'but',\n",
       " 'if',\n",
       " 'you',\n",
       " 'are',\n",
       " 'not',\n",
       " 'planning',\n",
       " 'on',\n",
       " 'going',\n",
       " 'to',\n",
       " 'see',\n",
       " 'the',\n",
       " 'historic',\n",
       " 'sites',\n",
       " 'in',\n",
       " 'beijing',\n",
       " 'then',\n",
       " 'you',\n",
       " 'will',\n",
       " 'be',\n",
       " 'ok',\n",
       " 'chose',\n",
       " 'to',\n",
       " 'have',\n",
       " 'some',\n",
       " 'breakfast',\n",
       " 'in',\n",
       " 'the',\n",
       " 'hotel',\n",
       " 'which',\n",
       " 'was',\n",
       " 'really',\n",
       " 'tasty',\n",
       " 'and',\n",
       " 'there',\n",
       " 'was',\n",
       " 'good',\n",
       " 'selection',\n",
       " 'of',\n",
       " 'dishes',\n",
       " 'there',\n",
       " 'are',\n",
       " 'couple',\n",
       " 'of',\n",
       " 'computers',\n",
       " 'to',\n",
       " 'use',\n",
       " 'in',\n",
       " 'the',\n",
       " 'communal',\n",
       " 'area',\n",
       " 'as',\n",
       " 'well',\n",
       " 'as',\n",
       " 'pool',\n",
       " 'table',\n",
       " 'there',\n",
       " 'is',\n",
       " 'also',\n",
       " 'small',\n",
       " 'swimming',\n",
       " 'pool',\n",
       " 'and',\n",
       " 'gym',\n",
       " 'area',\n",
       " 'would',\n",
       " 'definitely',\n",
       " 'stay',\n",
       " 'in',\n",
       " 'this',\n",
       " 'hotel',\n",
       " 'again',\n",
       " 'but',\n",
       " 'only',\n",
       " 'if',\n",
       " 'did',\n",
       " 'not',\n",
       " 'plan',\n",
       " 'to',\n",
       " 'travel',\n",
       " 'to',\n",
       " 'central',\n",
       " 'beijing',\n",
       " 'as',\n",
       " 'it',\n",
       " 'can',\n",
       " 'take',\n",
       " 'long',\n",
       " 'time',\n",
       " 'the',\n",
       " 'location',\n",
       " 'is',\n",
       " 'ok',\n",
       " 'if',\n",
       " 'you',\n",
       " 'plan',\n",
       " 'to',\n",
       " 'do',\n",
       " 'lot',\n",
       " 'of',\n",
       " 'shopping',\n",
       " 'as',\n",
       " 'there',\n",
       " 'is',\n",
       " 'big',\n",
       " 'shopping',\n",
       " 'centre',\n",
       " 'just',\n",
       " 'few',\n",
       " 'minutes',\n",
       " 'away',\n",
       " 'from',\n",
       " 'the',\n",
       " 'hotel',\n",
       " 'and',\n",
       " 'there',\n",
       " 'are',\n",
       " 'plenty',\n",
       " 'of',\n",
       " 'eating',\n",
       " 'options',\n",
       " 'around',\n",
       " 'including',\n",
       " 'restaurants',\n",
       " 'that',\n",
       " 'serve',\n",
       " 'dog',\n",
       " 'meat']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show the first entry in the documents list of lists\n",
    "documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Word2Vec model\n",
    "\n",
    "Training the model is fairly straightforward. You just instantiate Word2Vec and pass in the documents. Where each list within the main list contains a set of tokens from a user review. Word2Vec uses all these tokens to internally create a vocabulary, which is a unique set words.\n",
    "\n",
    "After building the vocabulary, we just need to call train(...) to start training the Word2Vec model. Training on this dataset takes about 10 minutes so please be patient. This trains a simple neural network with a single hidden layer with the goal of learning the weights of the hidden layer. These weights are essentially the word vectors that we’re trying to learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-23 10:58:40,467 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2018-10-23 10:58:40,469 : INFO : collecting all words and their counts\n",
      "2018-10-23 10:58:40,471 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-10-23 10:58:41,044 : INFO : PROGRESS: at sentence #10000, processed 1655714 words, keeping 25777 word types\n",
      "2018-10-23 10:58:41,616 : INFO : PROGRESS: at sentence #20000, processed 3317863 words, keeping 35016 word types\n",
      "2018-10-23 10:58:42,316 : INFO : PROGRESS: at sentence #30000, processed 5264072 words, keeping 47518 word types\n",
      "2018-10-23 10:58:42,917 : INFO : PROGRESS: at sentence #40000, processed 7081746 words, keeping 56675 word types\n",
      "2018-10-23 10:58:43,576 : INFO : PROGRESS: at sentence #50000, processed 9089491 words, keeping 63744 word types\n",
      "2018-10-23 10:58:44,215 : INFO : PROGRESS: at sentence #60000, processed 11013723 words, keeping 76780 word types\n",
      "2018-10-23 10:58:44,781 : INFO : PROGRESS: at sentence #70000, processed 12637525 words, keeping 83193 word types\n",
      "2018-10-23 10:58:45,297 : INFO : PROGRESS: at sentence #80000, processed 14099751 words, keeping 88453 word types\n",
      "2018-10-23 10:58:45,868 : INFO : PROGRESS: at sentence #90000, processed 15662149 words, keeping 93351 word types\n",
      "2018-10-23 10:58:46,441 : INFO : PROGRESS: at sentence #100000, processed 17164487 words, keeping 97880 word types\n",
      "2018-10-23 10:58:46,980 : INFO : PROGRESS: at sentence #110000, processed 18652292 words, keeping 102126 word types\n",
      "2018-10-23 10:58:47,515 : INFO : PROGRESS: at sentence #120000, processed 20152529 words, keeping 105917 word types\n",
      "2018-10-23 10:58:48,095 : INFO : PROGRESS: at sentence #130000, processed 21684330 words, keeping 110098 word types\n",
      "2018-10-23 10:58:48,673 : INFO : PROGRESS: at sentence #140000, processed 23330206 words, keeping 114102 word types\n",
      "2018-10-23 10:58:49,214 : INFO : PROGRESS: at sentence #150000, processed 24838754 words, keeping 118168 word types\n",
      "2018-10-23 10:58:49,785 : INFO : PROGRESS: at sentence #160000, processed 26390910 words, keeping 118664 word types\n",
      "2018-10-23 10:58:50,315 : INFO : PROGRESS: at sentence #170000, processed 27913916 words, keeping 123349 word types\n",
      "2018-10-23 10:58:50,873 : INFO : PROGRESS: at sentence #180000, processed 29535612 words, keeping 126741 word types\n",
      "2018-10-23 10:58:51,407 : INFO : PROGRESS: at sentence #190000, processed 31096459 words, keeping 129840 word types\n",
      "2018-10-23 10:58:51,998 : INFO : PROGRESS: at sentence #200000, processed 32805271 words, keeping 133248 word types\n",
      "2018-10-23 10:58:52,550 : INFO : PROGRESS: at sentence #210000, processed 34434198 words, keeping 136357 word types\n",
      "2018-10-23 10:58:53,092 : INFO : PROGRESS: at sentence #220000, processed 36083482 words, keeping 139411 word types\n",
      "2018-10-23 10:58:53,666 : INFO : PROGRESS: at sentence #230000, processed 37571762 words, keeping 142392 word types\n",
      "2018-10-23 10:58:54,219 : INFO : PROGRESS: at sentence #240000, processed 39138190 words, keeping 145225 word types\n",
      "2018-10-23 10:58:54,759 : INFO : PROGRESS: at sentence #250000, processed 40695049 words, keeping 147959 word types\n",
      "2018-10-23 10:58:55,045 : INFO : collected 150052 word types from a corpus of 41519355 raw words and 255404 sentences\n",
      "2018-10-23 10:58:55,046 : INFO : Loading a fresh vocabulary\n",
      "2018-10-23 10:58:55,400 : INFO : min_count=2 retains 70538 unique words (47% of original 150052, drops 79514)\n",
      "2018-10-23 10:58:55,401 : INFO : min_count=2 leaves 41439841 word corpus (99% of original 41519355, drops 79514)\n",
      "2018-10-23 10:58:55,660 : INFO : deleting the raw counts dictionary of 150052 items\n",
      "2018-10-23 10:58:55,669 : INFO : sample=0.001 downsamples 55 most-common words\n",
      "2018-10-23 10:58:55,670 : INFO : downsampling leaves estimated 30349257 word corpus (73.2% of prior 41439841)\n",
      "2018-10-23 10:58:55,670 : INFO : estimated required memory for 70538 words and 150 dimensions: 119914600 bytes\n",
      "2018-10-23 10:58:56,048 : INFO : resetting layer weights\n",
      "2018-10-23 10:58:56,916 : INFO : training model with 10 workers on 70538 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2018-10-23 10:58:56,917 : INFO : expecting 255404 sentences, matching count from corpus used for vocabulary survey\n",
      "2018-10-23 10:58:57,930 : INFO : PROGRESS: at 0.96% examples, 1467719 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 10:58:58,933 : INFO : PROGRESS: at 1.90% examples, 1479070 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 10:58:59,949 : INFO : PROGRESS: at 2.69% examples, 1462337 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 10:59:00,955 : INFO : PROGRESS: at 3.48% examples, 1448232 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 10:59:01,968 : INFO : PROGRESS: at 4.22% examples, 1437292 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 10:59:02,977 : INFO : PROGRESS: at 5.05% examples, 1430362 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 10:59:03,979 : INFO : PROGRESS: at 6.06% examples, 1425570 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 10:59:04,997 : INFO : PROGRESS: at 7.07% examples, 1423723 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 10:59:06,006 : INFO : PROGRESS: at 8.08% examples, 1422008 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 10:59:07,012 : INFO : PROGRESS: at 8.95% examples, 1396615 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 10:59:08,023 : INFO : PROGRESS: at 9.91% examples, 1393499 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 10:59:09,028 : INFO : PROGRESS: at 10.80% examples, 1388337 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 10:59:10,028 : INFO : PROGRESS: at 11.75% examples, 1386665 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 10:59:11,030 : INFO : PROGRESS: at 12.69% examples, 1383672 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 10:59:12,035 : INFO : PROGRESS: at 13.64% examples, 1382393 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 10:59:13,038 : INFO : PROGRESS: at 14.54% examples, 1381357 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 10:59:14,051 : INFO : PROGRESS: at 15.37% examples, 1373643 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 10:59:15,051 : INFO : PROGRESS: at 16.04% examples, 1355044 words/s, in_qsize 18, out_qsize 0\n",
      "2018-10-23 10:59:16,060 : INFO : PROGRESS: at 16.83% examples, 1346008 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 10:59:17,067 : INFO : PROGRESS: at 17.73% examples, 1343759 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-23 10:59:18,071 : INFO : PROGRESS: at 18.63% examples, 1342499 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 10:59:19,074 : INFO : PROGRESS: at 19.51% examples, 1338968 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-23 10:59:20,079 : INFO : PROGRESS: at 20.40% examples, 1337900 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 10:59:21,081 : INFO : PROGRESS: at 21.24% examples, 1335818 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 10:59:22,086 : INFO : PROGRESS: at 22.02% examples, 1334306 words/s, in_qsize 16, out_qsize 3\n",
      "2018-10-23 10:59:23,095 : INFO : PROGRESS: at 22.72% examples, 1330682 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-23 10:59:24,115 : INFO : PROGRESS: at 23.47% examples, 1330112 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 10:59:25,123 : INFO : PROGRESS: at 24.14% examples, 1328340 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 10:59:26,134 : INFO : PROGRESS: at 24.83% examples, 1323420 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 10:59:27,139 : INFO : PROGRESS: at 25.78% examples, 1323565 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 10:59:28,151 : INFO : PROGRESS: at 26.65% examples, 1319651 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 10:59:29,173 : INFO : PROGRESS: at 27.55% examples, 1318354 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 10:59:30,174 : INFO : PROGRESS: at 28.53% examples, 1319614 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 10:59:31,193 : INFO : PROGRESS: at 29.45% examples, 1318228 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 10:59:32,205 : INFO : PROGRESS: at 30.34% examples, 1316527 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 10:59:33,212 : INFO : PROGRESS: at 31.22% examples, 1315779 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-23 10:59:34,214 : INFO : PROGRESS: at 32.13% examples, 1315921 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 10:59:35,216 : INFO : PROGRESS: at 33.12% examples, 1318006 words/s, in_qsize 19, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-23 10:59:36,230 : INFO : PROGRESS: at 34.01% examples, 1318535 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 10:59:37,234 : INFO : PROGRESS: at 34.96% examples, 1319805 words/s, in_qsize 20, out_qsize 0\n",
      "2018-10-23 10:59:38,240 : INFO : PROGRESS: at 35.76% examples, 1318846 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 10:59:39,248 : INFO : PROGRESS: at 36.63% examples, 1318298 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 10:59:40,258 : INFO : PROGRESS: at 37.48% examples, 1317101 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-23 10:59:41,261 : INFO : PROGRESS: at 38.39% examples, 1316326 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 10:59:42,270 : INFO : PROGRESS: at 39.26% examples, 1315340 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 10:59:43,277 : INFO : PROGRESS: at 40.16% examples, 1315370 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 10:59:44,280 : INFO : PROGRESS: at 40.98% examples, 1313688 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 10:59:45,285 : INFO : PROGRESS: at 41.78% examples, 1312237 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-23 10:59:46,307 : INFO : PROGRESS: at 42.48% examples, 1311935 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 10:59:47,315 : INFO : PROGRESS: at 43.27% examples, 1312605 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 10:59:48,321 : INFO : PROGRESS: at 44.00% examples, 1313588 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 10:59:49,325 : INFO : PROGRESS: at 44.76% examples, 1314171 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 10:59:50,325 : INFO : PROGRESS: at 45.72% examples, 1315636 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 10:59:51,328 : INFO : PROGRESS: at 46.65% examples, 1315075 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 10:59:52,331 : INFO : PROGRESS: at 47.53% examples, 1314740 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 10:59:53,340 : INFO : PROGRESS: at 48.40% examples, 1312058 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 10:59:54,340 : INFO : PROGRESS: at 49.16% examples, 1307646 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 10:59:55,347 : INFO : PROGRESS: at 49.95% examples, 1304563 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-23 10:59:56,351 : INFO : PROGRESS: at 50.78% examples, 1303719 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 10:59:57,352 : INFO : PROGRESS: at 51.65% examples, 1302710 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 10:59:58,353 : INFO : PROGRESS: at 52.53% examples, 1302209 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 10:59:59,371 : INFO : PROGRESS: at 53.36% examples, 1300190 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-23 11:00:00,382 : INFO : PROGRESS: at 54.20% examples, 1299468 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 11:00:01,384 : INFO : PROGRESS: at 55.06% examples, 1298712 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 11:00:02,389 : INFO : PROGRESS: at 55.86% examples, 1298022 words/s, in_qsize 20, out_qsize 0\n",
      "2018-10-23 11:00:03,391 : INFO : PROGRESS: at 56.69% examples, 1297524 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 11:00:04,405 : INFO : PROGRESS: at 57.56% examples, 1296917 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 11:00:05,409 : INFO : PROGRESS: at 58.48% examples, 1296994 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 11:00:06,419 : INFO : PROGRESS: at 59.37% examples, 1297230 words/s, in_qsize 20, out_qsize 1\n",
      "2018-10-23 11:00:07,430 : INFO : PROGRESS: at 60.27% examples, 1297367 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-23 11:00:08,450 : INFO : PROGRESS: at 61.12% examples, 1296999 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 11:00:09,453 : INFO : PROGRESS: at 61.91% examples, 1296591 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 11:00:10,463 : INFO : PROGRESS: at 62.58% examples, 1295963 words/s, in_qsize 20, out_qsize 0\n",
      "2018-10-23 11:00:11,463 : INFO : PROGRESS: at 63.32% examples, 1295581 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 11:00:12,463 : INFO : PROGRESS: at 63.99% examples, 1295157 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 11:00:13,469 : INFO : PROGRESS: at 64.66% examples, 1293796 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 11:00:14,480 : INFO : PROGRESS: at 65.45% examples, 1292448 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 11:00:15,491 : INFO : PROGRESS: at 66.36% examples, 1291619 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 11:00:16,503 : INFO : PROGRESS: at 67.19% examples, 1290616 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 11:00:17,509 : INFO : PROGRESS: at 68.08% examples, 1289956 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 11:00:18,512 : INFO : PROGRESS: at 69.03% examples, 1290011 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 11:00:19,513 : INFO : PROGRESS: at 69.92% examples, 1289892 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 11:00:20,520 : INFO : PROGRESS: at 70.79% examples, 1289937 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 11:00:21,533 : INFO : PROGRESS: at 71.66% examples, 1289277 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 11:00:22,538 : INFO : PROGRESS: at 72.52% examples, 1288763 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 11:00:23,539 : INFO : PROGRESS: at 73.36% examples, 1287645 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 11:00:24,547 : INFO : PROGRESS: at 74.16% examples, 1286630 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 11:00:25,553 : INFO : PROGRESS: at 75.01% examples, 1286166 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 11:00:26,554 : INFO : PROGRESS: at 75.79% examples, 1285613 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 11:00:27,573 : INFO : PROGRESS: at 76.62% examples, 1284915 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 11:00:28,574 : INFO : PROGRESS: at 77.46% examples, 1284695 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 11:00:29,578 : INFO : PROGRESS: at 78.30% examples, 1283570 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-23 11:00:30,582 : INFO : PROGRESS: at 79.18% examples, 1283526 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 11:00:31,585 : INFO : PROGRESS: at 80.03% examples, 1282939 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 11:00:32,589 : INFO : PROGRESS: at 80.85% examples, 1282668 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 11:00:33,621 : INFO : PROGRESS: at 81.58% examples, 1280803 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-23 11:00:34,621 : INFO : PROGRESS: at 82.29% examples, 1280537 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 11:00:35,637 : INFO : PROGRESS: at 82.96% examples, 1279392 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 11:00:36,646 : INFO : PROGRESS: at 83.65% examples, 1278889 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-23 11:00:37,657 : INFO : PROGRESS: at 84.35% examples, 1278403 words/s, in_qsize 16, out_qsize 3\n",
      "2018-10-23 11:00:38,662 : INFO : PROGRESS: at 85.03% examples, 1277939 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 11:00:39,673 : INFO : PROGRESS: at 85.91% examples, 1277238 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 11:00:40,683 : INFO : PROGRESS: at 86.79% examples, 1276775 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 11:00:41,693 : INFO : PROGRESS: at 87.63% examples, 1275958 words/s, in_qsize 18, out_qsize 2\n",
      "2018-10-23 11:00:42,695 : INFO : PROGRESS: at 88.48% examples, 1274827 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 11:00:43,697 : INFO : PROGRESS: at 89.30% examples, 1273475 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 11:00:44,706 : INFO : PROGRESS: at 90.12% examples, 1272571 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 11:00:45,715 : INFO : PROGRESS: at 90.81% examples, 1270564 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 11:00:46,723 : INFO : PROGRESS: at 91.60% examples, 1269174 words/s, in_qsize 19, out_qsize 1\n",
      "2018-10-23 11:00:47,727 : INFO : PROGRESS: at 92.35% examples, 1267486 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 11:00:48,736 : INFO : PROGRESS: at 93.15% examples, 1266171 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 11:00:49,739 : INFO : PROGRESS: at 93.94% examples, 1265286 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 11:00:50,747 : INFO : PROGRESS: at 94.69% examples, 1263838 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-23 11:00:51,750 : INFO : PROGRESS: at 95.41% examples, 1262516 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 11:00:52,750 : INFO : PROGRESS: at 96.11% examples, 1261110 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-23 11:00:53,751 : INFO : PROGRESS: at 96.86% examples, 1259985 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 11:00:54,752 : INFO : PROGRESS: at 97.63% examples, 1258865 words/s, in_qsize 19, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-23 11:00:55,755 : INFO : PROGRESS: at 98.42% examples, 1257673 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 11:00:56,758 : INFO : PROGRESS: at 99.18% examples, 1256487 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 11:00:57,726 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-10-23 11:00:57,733 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-10-23 11:00:57,745 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-10-23 11:00:57,746 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-10-23 11:00:57,747 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-10-23 11:00:57,751 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-10-23 11:00:57,755 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-10-23 11:00:57,758 : INFO : PROGRESS: at 99.99% examples, 1255716 words/s, in_qsize 2, out_qsize 1\n",
      "2018-10-23 11:00:57,759 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-10-23 11:00:57,761 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-10-23 11:00:57,766 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-10-23 11:00:57,767 : INFO : training on 207596775 raw words (151744831 effective words) took 120.8s, 1255744 effective words/s\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "train() got an unexpected keyword argument 'epochs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-10d7fbc22ca5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWord2Vec\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: train() got an unexpected keyword argument 'epochs'"
     ]
    }
   ],
   "source": [
    "model=gensim.models.Word2Vec(documents, size=150, window=10, min_count=2, workers=10)\n",
    "model.train(documents,total_examples=len(documents),epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output examples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words similar to target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-23 11:05:31,700 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('beautiful', 0.805040180683136),\n",
       " ('gorgeous', 0.7894525527954102),\n",
       " ('wonderful', 0.752912163734436),\n",
       " ('fabulous', 0.7523320317268372),\n",
       " ('fantastic', 0.7314372658729553),\n",
       " ('nice', 0.7262121438980103),\n",
       " ('delightful', 0.7214747667312622),\n",
       " ('fab', 0.7074022889137268),\n",
       " ('stunning', 0.6599923372268677),\n",
       " ('superb', 0.6401865482330322)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = \"lovely\"\n",
    "model.wv.most_similar (positive=w1, topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('glowing', 0.5727674961090088),\n",
       " ('reading', 0.5183002352714539),\n",
       " ('ta', 0.514641284942627),\n",
       " ('tripadviser', 0.48887932300567627),\n",
       " ('booking', 0.48840874433517456),\n",
       " ('divergent', 0.48663946986198425),\n",
       " ('reviewing', 0.4851156771183014),\n",
       " ('submit', 0.47704505920410156),\n",
       " ('frommers', 0.47204506397247314),\n",
       " ('favorable', 0.46634262800216675)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = [\"read\", \"book\", \"novel\"]\n",
    "model.wv.most_similar (positive=w1, topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('noticed', 0.36520916223526),\n",
       " ('heard', 0.3578993082046509),\n",
       " ('commented', 0.35024142265319824),\n",
       " ('mentioned', 0.3180111050605774),\n",
       " ('despite', 0.3080020546913147),\n",
       " ('misfortune', 0.3052464723587036),\n",
       " ('disparate', 0.3038405179977417),\n",
       " ('avaiblable', 0.3023104667663574),\n",
       " ('insinuated', 0.3008701801300049),\n",
       " ('experienced', 0.3007904887199402)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Choose a word and return the top 10 most similar but that are not like another word\n",
    "w1 = [\"read\"]\n",
    "w2 = [\"book\", \"novel\"]\n",
    "model.wv.most_similar (positive=w1,negative=w2,topn=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity between words\n",
    "\n",
    "This computes the cosine similarity between the two specified words using word vectors of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76028256130245975"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similarity between two different words\n",
    "model.wv.similarity(w1=\"dirty\",w2=\"smelly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26989221592147172"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similarity between two different words\n",
    "model.wv.similarity(w1=\"dirty\",w2=\"clean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the odd one out\n",
    "Use Word2Vec to find odd items given a list of items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'france'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which one is the odd one out in this list?\n",
    "model.wv.doesnt_match([\"cat\",\"dog\",\"france\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Training parameters\n",
    "\n",
    "model = gensim.models.Word2Vec (documents, size=150, window=10, min_count=2, workers=10)\n",
    "\n",
    "### size\n",
    "The size of the dense vector to represent each token or word. It can be good to experiment with different sizes. This tutorial used 150.\n",
    "\n",
    "### window\n",
    "The maximum distance between the target word and its neighboring word. If your neighbor's position is greater than the maximum window width to the left and the right, then, some neighbors are not considered as being related to the target word. In theory, a smaller window should give you terms that are more related. If you have lots of data, then the window size should not matter too much, as long as it's reasonably sized.\n",
    "\n",
    "### min_count\n",
    "Minimium frequency count of words. The model would ignore words that do not statisfy the min_count. Extremely infrequent words are usually unimportant, so its best to get rid of those. Unless your dataset is really tiny, this does not really affect the model.\n",
    "\n",
    "### workers\n",
    "How many threads to use. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test simple PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the PCA plot of the words in the first document.\n",
    "first_doc = documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_vec = []\n",
    "for w in first_doc:\n",
    "    vec = model.wv[w]\n",
    "    first_vec.append(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_vec = np.array(first_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(293, 150)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_vec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(293, 2)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=2)\n",
    "projected = pca.fit_transform(first_vec)\n",
    "projected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1abd054d30>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = projected[:, 0]\n",
    "y = projected[:, 1]\n",
    "plt.scatter(x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
